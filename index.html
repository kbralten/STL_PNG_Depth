<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>STL to Depthmap</title>
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/build/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/loaders/STLLoader.js"></script>
    <!-- OpenCV.js for contour detection -->
    <script async src="https://docs.opencv.org/4.x/opencv.js" onload="window.cvReady=true;"></script>
    <style>
        body {
            margin: 0;
            overflow: auto;
            font-family: 'Inter', sans-serif;
            background-color: #f0f2f5;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: flex-start;
            min-height: 100vh;
            padding: 1rem;
        }
        .container {
            display: flex;
            flex-wrap: wrap;
            gap: 1rem;
            justify-content: center;
            align-items: flex-start;
            padding: 1rem;
            width: 100%;
            max-width: 1200px;
        }
        .canvas-wrapper {
            background-color: #ffffff;
            border-radius: 0.75rem;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            padding: 1rem;
            text-align: center;
            flex: 1 1 45%;
            min-width: 300px;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            position: relative;
        }
        canvas {
            border-radius: 0.5rem;
            max-width: 100%;
            max-height: 400px;
            display: block;
            cursor: grab;
            object-fit: contain; /* Preserve aspect ratio */
        }
        canvas:active {
            cursor: grabbing;
        }
        h1 {
            color: #334155;
            margin-bottom: 1.5rem;
        }
        h2 {
            color: #475569;
            margin-bottom: 0.75rem;
        }
        .controls-container {
            margin-bottom: 1.5rem;
            background-color: #ffffff;
            padding: 1rem 2rem;
            border-radius: 0.75rem;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 0.75rem;
        }
        input[type="file"], select {
            padding: 0.5rem 1rem;
            border: 1px solid #cbd5e1;
            border-radius: 0.5rem;
            background-color: #f8fafc;
            cursor: pointer;
            font-size: 1rem;
            color: #475569;
            transition: all 0.2s ease-in-out;
            width: 100%;
            max-width: 250px;
        }
        input[type="file"]:hover, select:hover {
            border-color: #94a3b8;
            background-color: #e2e8f0;
        }
        .loading-message {
            font-size: 1rem;
            color: #64748b;
            font-style: italic;
        }
    </style>
</head>
<body>
    <h1 class="text-3xl font-bold text-gray-800 mb-6">STL to Depthmap</h1>
    
    <div class="controls-container">
        <label for="stlFileInput" class="text-lg font-medium text-gray-700">Upload an STL Model:</label>
        <input type="file" id="stlFileInput" accept=".stl">
        <div id="loadingMessage" class="loading-message hidden">Loading STL...</div>

        <label for="viewSelector" class="text-lg font-medium text-gray-700 mt-4">Select Depth Map View:</label>
        <select id="viewSelector">
            <option value="Front">Front</option>
            <option value="Back">Back</option>
            <option value="Left">Left</option>
            <option value="Right">Right</option>
            <option value="Top">Top</option>
            <option value="Bottom">Bottom</option>
        </select>
    </div>

    <div class="container">
        <div class="canvas-wrapper">
            <h2 class="text-xl font-semibold">Interactive View</h2>
            <canvas id="originalCanvas"></canvas>
        </div>
        <div class="canvas-wrapper">
            <h2 class="text-xl font-semibold">Extracted Grayscale Depth Map (Orthographic)</h2>
            <canvas id="depthCanvas"></canvas>
            <div class="mt-4 flex gap-2 flex-wrap justify-center">
                <button id="downloadDepthBtn" class="px-4 py-2 bg-blue-600 text-white rounded hover:bg-blue-700 transition">Download Depth Map (PNG)</button>
                <button id="downloadSvgBtn" class="px-4 py-2 bg-green-600 text-white rounded hover:bg-green-700 transition">Download SVG</button>
            </div>
        </div>
        <div class="canvas-wrapper">
            <h2 class="text-xl font-semibold">SVG Preview with Transparency & Contours</h2>
            <div id="svgPreview" class="w-full border border-gray-300 rounded bg-white p-4 min-h-[300px] flex items-center justify-center">
                <p class="text-gray-500">SVG preview will appear here after loading a model</p>
            </div>
        </div>
    </div>

    <script>
        // Global variables for the scene
        let scene, camera, renderer;
        let depthScene, depthCamera; 
        let depthRenderTarget;
        let currentModel = null; 
        let currentDepthModel = null; 

        // Mouse interaction state for the original render
        let isDragging = false;
        let previousMousePosition = {
            x: 0,
            y: 0
        };

        const originalCanvas = document.getElementById('originalCanvas');
        const depthCanvas = document.getElementById('depthCanvas');
        const stlFileInput = document.getElementById('stlFileInput');
        const loadingMessage = document.getElementById('loadingMessage');
        const viewSelector = document.getElementById('viewSelector');

        // Set dimensions for the render target (and output canvases)
        const WIDTH = 512;
        const HEIGHT = 512;

        function init() {
            // --- Scene Setup ---
            scene = new THREE.Scene();
            scene.background = new THREE.Color(0xabcdef); 

            // The main camera for the original render
            camera = new THREE.PerspectiveCamera(75, WIDTH / HEIGHT, 0.1, 1000);
            camera.position.z = 5;
            camera.position.y = 2;
            camera.lookAt(0, 0, 0);

            renderer = new THREE.WebGLRenderer({ canvas: originalCanvas, antialias: true });
            renderer.setSize(WIDTH, HEIGHT);
            renderer.setPixelRatio(window.devicePixelRatio);
            renderer.shadowMap.enabled = true; 

            // Set canvas display size to maintain aspect ratio
            originalCanvas.style.width = WIDTH + 'px';
            originalCanvas.style.height = HEIGHT + 'px';

            // Add some lights
            const ambientLight = new THREE.AmbientLight(0x404040, 0.6); 
            scene.add(ambientLight);

            const directionalLight = new THREE.DirectionalLight(0xffffff, 1);
            directionalLight.position.set(5, 10, 7.5);
            directionalLight.castShadow = true;
            directionalLight.shadow.mapSize.width = 1024;
            directionalLight.shadow.mapSize.height = 1024;
            directionalLight.shadow.camera.near = 0.5;
            directionalLight.shadow.camera.far = 50;
            directionalLight.shadow.camera.left = -10;
            directionalLight.shadow.camera.right = 10;
            directionalLight.shadow.camera.top = 10;
            directionalLight.shadow.camera.bottom = -10;
            scene.add(directionalLight);

            // Add a ground plane (always present)
            const planeGeometry = new THREE.PlaneGeometry(10, 10);
            const planeMaterial = new THREE.MeshPhongMaterial({ color: 0xcccccc, side: THREE.DoubleSide });
            const plane = new THREE.Mesh(planeGeometry, planeMaterial);
            plane.rotation.x = -Math.PI / 2;
            plane.position.y = 0;
            plane.receiveShadow = true;
            scene.add(plane);

            // --- Depth Map Extraction Setup ---
            depthRenderTarget = new THREE.WebGLRenderTarget(WIDTH, HEIGHT, {
                minFilter: THREE.NearestFilter,
                magFilter: THREE.NearestFilter,
                format: THREE.RGBAFormat, 
                type: THREE.UnsignedByteType,
                stencilBuffer: false 
            });

            // Create a separate scene for rendering depth
            depthScene = new THREE.Scene();
            // The depth camera is now an OrthographicCamera
            depthCamera = new THREE.OrthographicCamera(
                WIDTH / -2, WIDTH / 2, 
                HEIGHT / 2, HEIGHT / -2, 
                -0.1, 1000 
            );
            depthCamera.position.z = 10; 

            const clonedPlane = plane.clone();
            clonedPlane.material = getDepthMaterial();
            depthScene.add(clonedPlane);

            // Setup event listeners
            stlFileInput.addEventListener('change', onSTLFileSelected);
            viewSelector.addEventListener('change', (event) => {
                if (currentModel) { 
                    setDepthCameraView(event.target.value);
                }
            });

            // Add mouse event listeners for interactive rotation and zooming
            originalCanvas.addEventListener('mousedown', onMouseDown);
            originalCanvas.addEventListener('mousemove', onMouseMove);
            originalCanvas.addEventListener('mouseup', onMouseUp);
            originalCanvas.addEventListener('mouseleave', onMouseUp); // Stop dragging if mouse leaves the canvas
            originalCanvas.addEventListener('wheel', onMouseWheel);

        }

        function loadSTLGeometry(data) {
            try {
                const loader = new THREE.STLLoader(); 
                const geometry = loader.parse(data);
                geometry.computeBoundingBox(); 

                const material = new THREE.MeshPhongMaterial({ color: 0x0077ff, specular: 0x444444, shininess: 20 });
                const mesh = new THREE.Mesh(geometry, material);

                // Clear previous model if any
                if (currentModel) {
                    scene.remove(currentModel);
                    currentModel.geometry.dispose();
                    currentModel.material.dispose();
                }
                if (currentDepthModel) {
                    depthScene.remove(currentDepthModel);
                    currentDepthModel.geometry.dispose();
                    currentDepthModel.material.dispose();
                }

                currentModel = mesh;
                currentModel.castShadow = true;
                currentModel.receiveShadow = true;
                scene.add(currentModel);

                // Clone the new model for the depth scene
                currentDepthModel = currentModel.clone();
                currentDepthModel.material = getDepthMaterial(); 
                depthScene.add(currentDepthModel);

                // Set initial views for both cameras independently
                setInitialObliqueView(); 
                const optimalView = determineOptimalDefaultView();
                viewSelector.value = optimalView;
                setDepthCameraView(optimalView); 

                loadingMessage.classList.add('hidden'); 
            } catch (error) {
                console.error("Error loading STL:", error);
                alert("Failed to load STL file. Please check the file format.");
                loadingMessage.classList.add('hidden'); 
            }
        }

        // Store the last uploaded STL filename (without extension)
        let lastSTLFilename = 'depthmap_highres';
        function onSTLFileSelected(event) {
            const file = event.target.files[0];
            if (!file) {
                return;
            }

            // Set the lastSTLFilename to the basename (without extension)
            let name = file.name || 'depthmap_highres';
            if (name.toLowerCase().endsWith('.stl')) {
                name = name.slice(0, -4);
            }
            lastSTLFilename = name;

            loadingMessage.classList.remove('hidden'); 

            const reader = new FileReader();
            reader.onload = (e) => {
                loadSTLGeometry(e.target.result);
            };
            reader.onerror = (error) => {
                console.error("Error reading file:", error);
                alert("Error reading file. Please try again.");
                loadingMessage.classList.add('hidden'); 
            };
            reader.readAsArrayBuffer(file);
        }

        function onMouseDown(event) {
            isDragging = true;
            previousMousePosition.x = event.clientX;
            previousMousePosition.y = event.clientY;
        }

        function onMouseMove(event) {
            if (!isDragging || !currentModel) return;

            const deltaX = event.clientX - previousMousePosition.x;
            const deltaY = event.clientY - previousMousePosition.y;

            // Get the model's center to rotate around
            const center = new THREE.Vector3();
            currentModel.geometry.boundingBox.getCenter(center);

            // Calculate rotation speed
            const speed = 0.005;

            // Rotate around the model's center
            const cameraPosition = camera.position.clone();
            
            cameraPosition.sub(center);
            
            // Apply horizontal rotation (around the model's local Y-axis)
            const horizontalQuaternion = new THREE.Quaternion().setFromAxisAngle(new THREE.Vector3(0, 1, 0), -deltaX * speed);
            cameraPosition.applyQuaternion(horizontalQuaternion);
            
            // Apply vertical rotation (around the camera's local X-axis)
            const verticalQuaternion = new THREE.Quaternion().setFromAxisAngle(camera.localToWorld(new THREE.Vector3(1, 0, 0)).sub(camera.position).normalize(), -deltaY * speed);
            cameraPosition.applyQuaternion(verticalQuaternion);
            
            cameraPosition.add(center);
            
            camera.position.copy(cameraPosition);
            camera.lookAt(center);
            
            previousMousePosition.x = event.clientX;
            previousMousePosition.y = event.clientY;
        }

        function onMouseUp() {
            isDragging = false;
        }

        function onMouseWheel(event) {
            if (!currentModel) return;

            event.preventDefault(); // Prevent page from scrolling
            
            const box = currentModel.geometry.boundingBox;
            const center = new THREE.Vector3();
            box.getCenter(center);
            
            const boundingSphere = new THREE.Sphere();
            currentModel.geometry.boundingBox.getBoundingSphere(boundingSphere);
            const radius = boundingSphere.radius;
            
            const zoomSpeed = 0.25; // Increased zoom speed
            
            // Get the direction vector from the center to the camera
            const direction = camera.position.clone().sub(center).normalize();
            
            // Calculate new distance based on wheel direction
            let newDistance = camera.position.distanceTo(center) + event.deltaY * zoomSpeed;

            // Clamp the distance to a reasonable range
            const minDistance = radius * 1.5; 
            const maxDistance = radius * 10;
            newDistance = Math.max(minDistance, Math.min(maxDistance, newDistance));

            // Set the new camera position
            camera.position.copy(center).add(direction.multiplyScalar(newDistance));
            camera.updateProjectionMatrix();
        }

        function getDepthMaterial() {
            // Vertex Shader: Pass position to fragment shader
            const vertexShader = `
                void main() {
                    gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
                }
            `;

            // Fragment Shader: Output linear depth directly from gl_FragCoord.z
            const fragmentShader = `
                out highp vec4 FragColor; 
                void main() {
                    FragColor = vec4(vec3(1.0 - gl_FragCoord.z), 1.0);
                }
            `;

            const material = new THREE.ShaderMaterial({
                vertexShader: vertexShader,
                fragmentShader: fragmentShader,
                glslVersion: THREE.GLSL3 
            });
            return material;
        }

        function setInitialObliqueView() {
            if (!currentModel || !currentModel.geometry.boundingBox) return;
            
            const box = currentModel.geometry.boundingBox;
            const center = new THREE.Vector3();
            box.getCenter(center);
            
            const boundingSphere = new THREE.Sphere();
            currentModel.geometry.boundingBox.getBoundingSphere(boundingSphere);
            const radius = boundingSphere.radius;
            
            // Set an initial oblique position
            camera.position.set(center.x + radius * 1.5, center.y + radius * 1.5, center.z + radius * 1.5);
            camera.lookAt(center);

            // Set perspective camera near/far based on the calculated distance and model radius
            const perspectiveDistance = camera.position.distanceTo(center);
            camera.near = Math.max(0.1, perspectiveDistance - radius * 2); 
            camera.far = perspectiveDistance + radius * 2; 
            
            // Safety check: ensure far is greater than near
            if (camera.far <= camera.near) {
                camera.far = camera.near + (radius > 0 ? radius * 5 : 10);
            }
            camera.updateProjectionMatrix();
        }

        function determineOptimalDefaultView() {
            // For CNC, a top-down view is usually preferred as a default.
            return 'Top'; 
        }

        function setDepthCameraView(orientation) {
            if (!currentModel || !currentModel.geometry.boundingBox) {
                console.warn("No model loaded or bounding box not available for depth camera adjustment.");
                return;
            }

            const box = currentModel.geometry.boundingBox;
            const center = new THREE.Vector3();
            box.getCenter(center);
            const size = new THREE.Vector3();
            box.getSize(size);

            const aspect = WIDTH / HEIGHT;

            let targetLookDir = new THREE.Vector3(); 
            let thickness = 0;
            
            switch (orientation) {
                case 'Front':
                    targetLookDir.set(0, 0, 1);
                    thickness = size.z;
                    break;
                case 'Back':
                    targetLookDir.set(0, 0, -1);
                    thickness = size.z;
                    break;
                case 'Left':
                    targetLookDir.set(-1, 0, 0);
                    thickness = size.x;
                    break;
                case 'Right':
                    targetLookDir.set(1, 0, 0);
                    thickness = size.x;
                    break;
                case 'Top':
                    targetLookDir.set(0, 1, 0);
                    thickness = size.y;
                    break;
                case 'Bottom':
                    targetLookDir.set(0, -1, 0);
                    thickness = size.y;
                    break;
                default:
                    console.warn("Unknown orientation:", orientation);
                    return;
            }

            // Position the orthographic camera at the center of the model's bounding box,
            // then offset it slightly along the viewing direction.
            const modelDiagonal = size.length();
            const orthoCamOffset = (modelDiagonal > 0) ? modelDiagonal * 0.75 : 5; 
            depthCamera.position.copy(center).add(targetLookDir.clone().multiplyScalar(orthoCamOffset));
            depthCamera.lookAt(center);

            // Use the calculated thickness to set the near and far planes
            const dist = depthCamera.position.distanceTo(center);
            depthCamera.near = dist - (thickness / 2) - 0.1;
            depthCamera.far = dist + (thickness / 2) + 0.1;

            if (depthCamera.far <= depthCamera.near) {
                depthCamera.far = depthCamera.near + thickness + 1;
            }

            let frustumWidth = 0;
            let frustumHeight = 0;

            if (orientation === 'Top' || orientation === 'Bottom') {
                frustumWidth = size.x;
                frustumHeight = size.z;
            } else if (orientation === 'Left' || orientation === 'Right') {
                frustumWidth = size.y;
                frustumHeight = size.z;
            } else if (orientation === 'Front' || orientation === 'Back') {
                frustumWidth = size.x;
                frustumHeight = size.y;
            }

            if (frustumWidth / frustumHeight > aspect) { 
                frustumHeight = frustumWidth / aspect;
            } else { 
                frustumWidth = frustumHeight * aspect;
            }

            const margin = Math.max(frustumWidth, frustumHeight) * 0.1;
            depthCamera.left = (frustumWidth / -2) - margin;
            depthCamera.right = (frustumWidth / 2) + margin;
            depthCamera.top = (frustumHeight / 2) + margin;
            depthCamera.bottom = (frustumHeight / -2) - margin;
            
            depthCamera.updateProjectionMatrix();
            
            // Update SVG preview when view changes
            setTimeout(() => updateSVGPreviewAsync(), 100);
        }

        // Store the latest raw depth pixel buffer for use in both canvas and SVG
        let lastRawDepthPixelBuffer = null;
        let lastRawDepthWidth = 0;
        let lastRawDepthHeight = 0;

        function animate() {
            requestAnimationFrame(animate);

            // Update the loaded model's transformations in the depth scene to match the main scene
            if (currentModel && currentDepthModel) {
                currentDepthModel.position.copy(currentModel.position);
                currentDepthModel.rotation.copy(currentModel.rotation);
                currentDepthModel.scale.copy(currentModel.scale);
            }

            // Render the main scene to the canvas
            renderer.setRenderTarget(null); 
            renderer.render(scene, camera);

            // Render depth scene to render target
            renderer.setRenderTarget(depthRenderTarget);
            renderer.render(depthScene, depthCamera);

            // Read pixels from the depth texture and display on 2D canvas
            readDepthPixels();
        }

        function readDepthPixels() {
            const pixelBuffer = new Uint8Array(4 * WIDTH * HEIGHT);
            renderer.readRenderTargetPixels(depthRenderTarget, 0, 0, WIDTH, HEIGHT, pixelBuffer);

            // Store the raw buffer for SVG and canvas use
            lastRawDepthPixelBuffer = pixelBuffer.slice();
            lastRawDepthWidth = WIDTH;
            lastRawDepthHeight = HEIGHT;

            // Draw the raw (non-transparent) grayscale image to the 2D canvas
            depthCanvas.width = WIDTH;
            depthCanvas.height = HEIGHT;
            
            // Set canvas display size to maintain aspect ratio
            depthCanvas.style.width = WIDTH + 'px';
            depthCanvas.style.height = HEIGHT + 'px';
            
            const context = depthCanvas.getContext('2d');
            const imageData = context.createImageData(WIDTH, HEIGHT);

            // Flip the image vertically: WebGL reads pixels with Y=0 at bottom, canvas expects Y=0 at top
            for (let y = 0; y < HEIGHT; y++) {
                for (let x = 0; x < WIDTH; x++) {
                    const srcIndex = ((HEIGHT - 1 - y) * WIDTH + x) * 4; // Flip Y coordinate
                    const dstIndex = (y * WIDTH + x) * 4;
                    const r = pixelBuffer[srcIndex];
                    imageData.data[dstIndex + 0] = r;
                    imageData.data[dstIndex + 1] = r;
                    imageData.data[dstIndex + 2] = r;
                    imageData.data[dstIndex + 3] = 255; // Always opaque for 2D canvas
                }
            }
            context.putImageData(imageData, 0, 0);
        }

        window.addEventListener('resize', () => {
            // This example uses fixed resolution canvases, so resizing the window
            // does not change the render target size or canvas resolution.
            // If dynamic resizing is needed, update WIDTH/HEIGHT, renderer size,
            // camera aspect, and render target size here.
        });

        // Download depth map as PNG and SVG
        document.addEventListener('DOMContentLoaded', function () {
            const downloadBtn = document.getElementById('downloadDepthBtn');
            if (downloadBtn) {
                downloadBtn.addEventListener('click', function () {
                    renderHighResDepthMapAndDownload();
                });
            }
            
            const downloadSvgBtn = document.getElementById('downloadSvgBtn');
            if (downloadSvgBtn) {
                downloadSvgBtn.addEventListener('click', function () {
                    generateAndDownloadSVG();
                });
            }
        });

        // High-res depth map rendering and download
        function renderHighResDepthMapAndDownload() {
            if (!currentDepthModel || !currentModel) {
                alert("No model loaded.");
                return;
            }
            
            const orientation = viewSelector.value;

            // Determine high-res size (long side = 4000px)
            const box = currentModel.geometry.boundingBox;
            const size = new THREE.Vector3();
            box.getSize(size);

            let frustumWidth = 0;
            let frustumHeight = 0;

            if (orientation === 'Top' || orientation === 'Bottom') {
                frustumWidth = size.x;
                frustumHeight = size.z;
            } else if (orientation === 'Left' || orientation === 'Right') {
                frustumWidth = size.y;
                frustumHeight = size.z;
            } else if (orientation === 'Front' || orientation === 'Back') {
                frustumWidth = size.x;
                frustumHeight = size.y;
            }

            const aspect = frustumWidth / frustumHeight;

            const longSide = 4000;
            let highResWidth, highResHeight;
            if (aspect >= 1) {
                highResWidth = longSide;
                highResHeight = Math.round(longSide / aspect);
            } else {
                highResHeight = longSide;
                highResWidth = Math.round(longSide * aspect);
            }

            // Create a new renderer and render target for high-res
            const highResRenderer = new THREE.WebGLRenderer({ preserveDrawingBuffer: true });
            highResRenderer.setSize(highResWidth, highResHeight);
            highResRenderer.setPixelRatio(1);

            const highResRenderTarget = new THREE.WebGLRenderTarget(highResWidth, highResHeight, {
                minFilter: THREE.NearestFilter,
                magFilter: THREE.NearestFilter,
                format: THREE.RGBAFormat,
                type: THREE.UnsignedByteType,
                stencilBuffer: false
            });

            // Clone the depth camera and adjust for high-res aspect/frustum
            const highResCamera = depthCamera.clone();
            
            // Adjust frustum for new aspect ratio
            let camAspect = highResWidth / highResHeight;
            let finalFrustumWidth, finalFrustumHeight;

            if (frustumWidth / frustumHeight > camAspect) {
                finalFrustumWidth = frustumWidth;
                finalFrustumHeight = frustumWidth / camAspect;
            } else {
                finalFrustumHeight = frustumHeight;
                finalFrustumWidth = frustumHeight * camAspect;
            }
            
            const centerX = (highResCamera.left + highResCamera.right) / 2;
            const centerY = (highResCamera.top + highResCamera.bottom) / 2;
            highResCamera.left = centerX - finalFrustumWidth / 2;
            highResCamera.right = centerX + finalFrustumWidth / 2;
            highResCamera.top = centerY + finalFrustumHeight / 2;
            highResCamera.bottom = centerY - finalFrustumHeight / 2;

            highResCamera.updateProjectionMatrix();

            // Render to high-res target
            highResRenderer.setRenderTarget(highResRenderTarget);
            highResRenderer.render(depthScene, highResCamera);

            // Read pixels
            const pixelBuffer = new Uint8Array(4 * highResWidth * highResHeight);
            highResRenderer.readRenderTargetPixels(highResRenderTarget, 0, 0, highResWidth, highResHeight, pixelBuffer);

            // Create offscreen canvas for PNG
            const offCanvas = document.createElement('canvas');
            offCanvas.width = highResWidth;
            offCanvas.height = highResHeight;
            const ctx = offCanvas.getContext('2d');
            const imageData = ctx.createImageData(highResWidth, highResHeight);

            // Flip the image vertically: WebGL reads pixels with Y=0 at bottom, canvas expects Y=0 at top
            for (let y = 0; y < highResHeight; y++) {
                for (let x = 0; x < highResWidth; x++) {
                    const srcIndex = ((highResHeight - 1 - y) * highResWidth + x) * 4; // Flip Y coordinate
                    const dstIndex = (y * highResWidth + x) * 4;
                    
                    const r = pixelBuffer[srcIndex];
                    imageData.data[dstIndex + 0] = r;
                    imageData.data[dstIndex + 1] = r;
                    imageData.data[dstIndex + 2] = r;
                    // If pure black, set alpha to 0 (transparent), else 255 (opaque)
                    imageData.data[dstIndex + 3] = (r === 0) ? 0 : 255;
                }
            }
            ctx.putImageData(imageData, 0, 0);

            // Download
            offCanvas.toBlob(function(blob) {
                const url = URL.createObjectURL(blob);
                const link = document.createElement('a');
                link.href = url;
                link.download = lastSTLFilename + '_depthmap.png';
                document.body.appendChild(link);
                link.click();
                document.body.removeChild(link);
                URL.revokeObjectURL(url);
            }, 'image/png');
        }


        // Use OpenCV.js to find contours from a pixel buffer
        function findContoursFromPixelBuffer(pixelBuffer, width, height) {
            if (!window.cvReady || typeof cv === 'undefined') {
                throw new Error('OpenCV.js is not loaded yet.');
            }
            // Step 1: Create grayscale image from pixel buffer with Y-flip
            let src = cv.Mat.zeros(height, width, cv.CV_8UC1);
            for (let y = 0; y < height; y++) {
                for (let x = 0; x < width; x++) {
                    const srcIndex = ((height - 1 - y) * width + x) * 4; // Y-flip
                    src.ucharPtr(y, x)[0] = pixelBuffer[srcIndex];
                }
            }
            // Step 2: Threshold to binary (pure black <=2 becomes 255, else 0)
            let mask = new cv.Mat();
            cv.threshold(src, mask, 0, 255, cv.THRESH_BINARY);
            // Step 3: Add 1-pixel border (like cv2.copyMakeBorder)
            let padded = new cv.Mat();
            cv.copyMakeBorder(mask, padded, 1, 1, 1, 1, cv.BORDER_CONSTANT, new cv.Scalar(0));
            // Step 4: Find contours
            let contours = new cv.MatVector();
            let hierarchy = new cv.Mat();
            cv.findContours(padded, contours, hierarchy, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE);
            // Convert contours to JS arrays, remove largest contour (outermost boundary)
            let jsContours = [];
            for (let i = 0; i < contours.size(); i++) {
                let cnt = contours.get(i);
                let arr = [];
                for (let j = 0; j < cnt.data32S.length; j += 2) {
                    // Remove border offset
                    arr.push([cnt.data32S[j] - 1, cnt.data32S[j + 1] - 1]);
                }
                jsContours.push(arr);
                cnt.delete();
            }

            src.delete();
            mask.delete();
            padded.delete();
            hierarchy.delete();
            contours.delete();
            return jsContours;
        }
        
        // Update SVG preview asynchronously (smaller resolution for preview)
        function updateSVGPreviewAsync() {
            if (!currentDepthModel || !currentModel) {
                return;
            }
            
            try {
                const svgContent = generateSVGContent(500); // Lower resolution for preview
                updateSVGPreview(svgContent);
            } catch (error) {
                console.error('Error generating SVG preview:', error);
                const svgPreview = document.getElementById('svgPreview');
                if (svgPreview) {
                    svgPreview.innerHTML = '<p class="text-red-500">Error generating SVG preview</p>';
                }
            }
        }

        // Generate SVG content with specified resolution
        function generateSVGContent(maxResolution = 1000) {
            if (!currentDepthModel || !currentModel) {
                throw new Error("No model loaded");
            }

            // Get model dimensions for SVG scaling
            const box = currentModel.geometry.boundingBox;
            const size = new THREE.Vector3();
            box.getSize(size);
            
            const orientation = viewSelector.value;
            let svgWidth, svgHeight;

            if (orientation === 'Top' || orientation === 'Bottom') {
                svgWidth = size.x;
                svgHeight = size.z;
            } else if (orientation === 'Left' || orientation === 'Right') {
                svgWidth = size.y;
                svgHeight = size.z;
            } else if (orientation === 'Front' || orientation === 'Back') {
                svgWidth = size.x;
                svgHeight = size.y;
            }

            // Calculate resolution
            const aspect = svgWidth / svgHeight;
            let highResWidth, highResHeight;
            
            if (aspect >= 1) {
                highResWidth = maxResolution;
                highResHeight = Math.round(maxResolution / aspect);
            } else {
                highResHeight = maxResolution;
                highResWidth = Math.round(maxResolution * aspect);
            }

            // Create renderer for SVG generation
            const svgRenderer = new THREE.WebGLRenderer({ preserveDrawingBuffer: true });
            svgRenderer.setSize(highResWidth, highResHeight);
            svgRenderer.setPixelRatio(1);

            const svgRenderTarget = new THREE.WebGLRenderTarget(highResWidth, highResHeight, {
                minFilter: THREE.NearestFilter,
                magFilter: THREE.NearestFilter,
                format: THREE.RGBAFormat,
                type: THREE.UnsignedByteType,
                stencilBuffer: false
            });

            // Clone and adjust camera
            const svgCamera = depthCamera.clone();
            let frustumWidth, frustumHeight;

            if (orientation === 'Top' || orientation === 'Bottom') {
                frustumWidth = size.x;
                frustumHeight = size.z;
            } else if (orientation === 'Left' || orientation === 'Right') {
                frustumWidth = size.y;
                frustumHeight = size.z;
            } else if (orientation === 'Front' || orientation === 'Back') {
                frustumWidth = size.x;
                frustumHeight = size.y;
            }

            let camAspect = highResWidth / highResHeight;
            let finalFrustumWidth, finalFrustumHeight;

            if (frustumWidth / frustumHeight > camAspect) {
                finalFrustumWidth = frustumWidth;
                finalFrustumHeight = frustumWidth / camAspect;
            } else {
                finalFrustumHeight = frustumHeight;
                finalFrustumWidth = frustumHeight * camAspect;
            }
            
            const centerX = (svgCamera.left + svgCamera.right) / 2;
            const centerY = (svgCamera.top + svgCamera.bottom) / 2;
            svgCamera.left = centerX - finalFrustumWidth / 2;
            svgCamera.right = centerX + finalFrustumWidth / 2;
            svgCamera.top = centerY + finalFrustumHeight / 2;
            svgCamera.bottom = centerY - finalFrustumHeight / 2;

            svgCamera.updateProjectionMatrix();

            // Render to target
            svgRenderer.setRenderTarget(svgRenderTarget);
            svgRenderer.render(depthScene, svgCamera);

            // Read pixels
            const pixelBuffer = new Uint8Array(4 * highResWidth * highResHeight);
            svgRenderer.readRenderTargetPixels(svgRenderTarget, 0, 0, highResWidth, highResHeight, pixelBuffer);

            // Step 1: Find contours using original pixel buffer values (before any transparency)
            // Following the Python approach: find contours around black holes first
            const contours = findContoursFromPixelBuffer(pixelBuffer, highResWidth, highResHeight);

            // Step 2: Create canvas with transparency for SVG PNG
            const canvas = document.createElement('canvas');
            canvas.width = highResWidth;
            canvas.height = highResHeight;
            const ctx = canvas.getContext('2d');
            const imageData = ctx.createImageData(highResWidth, highResHeight);

            // Process pixels with transparency (black and white become transparent)
            for (let y = 0; y < highResHeight; y++) {
                for (let x = 0; x < highResWidth; x++) {
                    const srcIndex = ((highResHeight - 1 - y) * highResWidth + x) * 4;
                    const dstIndex = (y * highResWidth + x) * 4;
                    const r = pixelBuffer[srcIndex];
                    imageData.data[dstIndex + 0] = r;
                    imageData.data[dstIndex + 1] = r;
                    imageData.data[dstIndex + 2] = r;
                    // Make black (0) and white (255) transparent, gray values opaque
                    imageData.data[dstIndex + 3] = (r <= 0 || r >= 255) ? 0 : 255;
                }
            }
            ctx.putImageData(imageData, 0, 0);

            // Convert canvas to base64 PNG
            const pngDataUrl = canvas.toDataURL('image/png');
            const base64Data = pngDataUrl.split(',')[1];
            
            // Generate SVG path elements from contours
            const pathElements = [];
            contours.forEach(contour => {
                //if (contour.length < 5) return; // Skip very small contours

                const points = contour.map(([x, y]) => {
                    // Convert pixel coordinates to SVG coordinates
                    const svgX = (x / highResWidth) * svgWidth;
                    const svgY = (y / highResHeight) * svgHeight;
                    return `${svgX},${svgY}`;
                });
                
                if (points.length > 0) {
                    const pathStr = "M " + points.join(" L ") + " Z";
                    pathElements.push(`<path d="${pathStr}" stroke="rgb(255,219,102)" fill="none" stroke-width="0.1" />`);
                }
            });

            // Generate SVG content
            const svgContent = `<?xml version="1.0" encoding="UTF-8"?>
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" 
     width="${svgWidth}mm" height="${svgHeight}mm" viewBox="0 0 ${svgWidth} ${svgHeight}">
    <image x="0" y="0" width="${svgWidth}" height="${svgHeight}" 
           xlink:href="data:image/png;base64,${base64Data}" />
    ${pathElements.join('\n    ')}
</svg>`;

            // Cleanup
            svgRenderer.dispose();
            
            return svgContent;
        }

        // Generate SVG with transparency and contours
        function generateAndDownloadSVG() {
            if (!currentDepthModel || !currentModel) {
                alert("No model loaded.");
                return;
            }

            try {
                const svgContent = generateSVGContent(1000); // High resolution for download
                
                // Update preview
                updateSVGPreview(svgContent);

                // Download SVG
                const blob = new Blob([svgContent], { type: 'image/svg+xml' });
                const url = URL.createObjectURL(blob);
                const link = document.createElement('a');
                link.href = url;
                link.download = lastSTLFilename + '_depthmap.svg';
                document.body.appendChild(link);
                link.click();
                document.body.removeChild(link);
                URL.revokeObjectURL(url);
            } catch (error) {
                console.error('Error generating SVG:', error);
                alert('Error generating SVG: ' + error.message);
            }
        }

        // Update SVG preview
        function updateSVGPreview(svgContent) {
            const svgPreview = document.getElementById('svgPreview');
            if (svgPreview) {
                svgPreview.innerHTML = svgContent;
                // Scale the SVG to fit the container
                const svgElement = svgPreview.querySelector('svg');
                if (svgElement) {
                    svgElement.style.maxWidth = '100%';
                    svgElement.style.maxHeight = '100%';
                    svgElement.style.height = 'auto';
                }
            }
        }

        window.onload = function () {
            init();
            animate();
        }
    </script>
</body>
</html>
